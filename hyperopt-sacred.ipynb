{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt using sacred\n",
    "The example function to optimize is:\n",
    "$$x^2+y^2$$\n",
    "\n",
    "Where x and y have added Gaussian noise with $\\mu=0$ and $\\sigma=1$.\n",
    "\n",
    "This document shows quick examples of sequential and parallel optimization.\n",
    "\n",
    "It is recommended to look at the example without sacred first as it has much better documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "import hyperopt\n",
    "from hyperopt import hp\n",
    "from hyperopt.mongoexp import MongoTrials\n",
    "\n",
    "# My imports\n",
    "import objective\n",
    "\n",
    "# Some parameters\n",
    "n_trials = 150\n",
    "local_avg_length = 15\n",
    "n_workers = 5\n",
    "jobs_per_worker = int(math.ceil(n_trials/n_workers))\n",
    "db_name = \"hopt-min-sacred\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = dict(x=hp.uniform(\"x\", -10, 10),\n",
    "                    y=hp.uniform(\"y\", -5, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a set of random sequential trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:49<00:00,  3.15it/s, best loss: 0.9888261762590211]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': 0.3592081814638135, 'y': 0.6988205327789254}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_trials_seq = hyperopt.Trials()\n",
    "hyperopt.fmin(objective.sacred_hyperopt_objective,\n",
    "              space=search_space,\n",
    "              algo=hyperopt.rand.suggest,\n",
    "              max_evals=n_trials,\n",
    "              trials=random_trials_seq,\n",
    "              verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a set of parallel TPE trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mongo://localhost:27184/hopt-min-sacred/jobs'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hopt_address = (f\"mongo://{os.environ['MONGO_WRITE_IP']}:{os.environ['MONGO_PORT']}/\" +\n",
    "                db_name + \"/jobs\")\n",
    "hopt_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195it [03:20,  1.03s/it, best loss: 0.4454398376557718]                         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': 1.6638083386117681, 'y': -0.7054565446930836}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the sub-processes\n",
    "for i in range(n_workers):\n",
    "    subprocess.Popen(f\"bash hopt-workerN.sh {db_name} {jobs_per_worker}\".split())\n",
    "\n",
    "# Run the actual optimization (should finish super fast)\n",
    "tpe_trials_par = MongoTrials(hopt_address, exp_key=\"tpe\")\n",
    "hyperopt.fmin(objective.sacred_hyperopt_objective,\n",
    "              space=search_space,\n",
    "              algo=hyperopt.tpe.suggest,\n",
    "              max_evals=n_trials,\n",
    "              trials=tpe_trials_par,\n",
    "              verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now launch omniboard with the following command and you should see a lot of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'omniboard -m localhost:27184:sacred'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"omniboard -m {os.environ['MONGO_WRITE_IP']}:{os.environ['MONGO_PORT']}:sacred\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
